{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9-16: Implementing a Neural Network from scratch using Python and NumPy\n",
    "\n",
    "2021060904008 - 周杰锋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 设计MLP解决 多分类问题 (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate data\n",
    "\n",
    "NUM_1 = np.array([[0,1,1,0,0],[0,0,1,0,0], [0,0,1,0,0], [0,0,1,0,0],[0,1,1,1,0]])\n",
    "NUM_2 = np.array([[1,1,1,1,0], [0,0,0,0,1],[0,1,1,1,0],[1,0,0,0,0],[1,1,1,1,1]])\n",
    "NUM_3 = np.array([[1,1,1,1,0],[0,0,0,0,1],[0,1,1,1,0],[0,0,0,0,1],[1,1,1,1,0]])\n",
    "NUM_4 = np.array([[0,0,0,1,0],[0,0,1,1,0],[0,1,0,1,0],[1,1,1,1,1],[0,0,0,1,0]])\n",
    "NUM_5 = np.array([[1,1,1,1,1],[1,0,0,0,0],[1,1,1,1,0],[0,0,0,0,1],[1,1,1,1,0]])\n",
    "\n",
    "X_train = np.array([NUM_1, NUM_2, NUM_3, NUM_4, NUM_5]).reshape(5,-1)\n",
    "\n",
    "Y_train = np.array([[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]])\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, in_hidden_out:list, if_bias=False, seed=None):\n",
    "        self.input_size = in_hidden_out[0]\n",
    "        self.output_size = in_hidden_out[-1]\n",
    "        self.hidden_layers = len(in_hidden_out) - 2\n",
    "        self.in_hidden_out = in_hidden_out\n",
    "        self.if_bias = if_bias\n",
    "        self.seed = seed\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.loss = []\n",
    "        self.activations = []\n",
    "        self.num_classes = in_hidden_out[-1]\n",
    "\n",
    "\n",
    "        self.initialize_weights_and_biases()\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    \n",
    "    def corss_entropy(self, y_pred, y_true):\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "\n",
    "    def MSD(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / exp_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    def initialize_weights_and_biases(self):\n",
    "        if self.seed:\n",
    "            np.random.seed(self.seed)\n",
    "        for i in range(self.hidden_layers + 1):\n",
    "            self.weights.append(np.random.rand(self.in_hidden_out[i], self.in_hidden_out[i+1]) * 2 -1)\n",
    "            if self.if_bias:\n",
    "                self.biases.append(np.random.rand((1, self.in_hidden_out[i+1]))*2 -1)\n",
    "            else:\n",
    "                self.biases.append(np.zeros((1, self.in_hidden_out[i+1])))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(self.hidden_layers + 1):\n",
    "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self.sigmoid(z)\n",
    "            self.activations.append(a)\n",
    "        # softmax output layer\n",
    "        self.activations[-1] = self.softmax(self.activations[-1])\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        _ = self.forward(X)\n",
    "        error = y - self.activations[-1]\n",
    "\n",
    "        self.loss.append(self.corss_entropy(self.activations[-1], y))\n",
    "\n",
    "        delta = error\n",
    "        self.weights[-1] += learning_rate * np.dot(self.activations[-2].T, delta)\n",
    "        if self.if_bias:\n",
    "            self.biases[-1] += learning_rate * np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "        for i in range(self.hidden_layers, 0, -1):\n",
    "            delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            self.weights[i-1] += learning_rate * np.dot(self.activations[i-1].T, delta)\n",
    "            if self.if_bias:\n",
    "                self.biases[i-1] += learning_rate * np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for _ in range(epochs):\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0]\n",
      " [1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1]\n",
      " [1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0]\n",
      " [0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 1 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== \t MLPClassifier Before Training \t =====\n",
      "[[0.13576873 0.15054844 0.30537435 0.13913304 0.26917545]\n",
      " [0.24646851 0.13339557 0.24173507 0.13147015 0.2469307 ]\n",
      " [0.25361505 0.1355886  0.22477188 0.12258736 0.2634371 ]\n",
      " [0.15586516 0.13997985 0.2789299  0.12738248 0.2978426 ]\n",
      " [0.22685594 0.14534138 0.25131373 0.12073819 0.25575077]]\n",
      "===== \t MLPClassifier After Training \t =====\n",
      "[[0.40460968 0.14884758 0.14884758 0.14884758 0.14884758]\n",
      " [0.14596971 0.3967701  0.16533306 0.14596356 0.14596356]\n",
      " [0.12435813 0.15426087 0.33804044 0.12435813 0.25898243]\n",
      " [0.14884758 0.14884758 0.14884758 0.40460968 0.14884758]\n",
      " [0.13878774 0.13878774 0.20637258 0.13878774 0.37726419]]\n",
      "===== \t Groud Truth \t =====\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLPClassifier = MLP([5*5, 50, 5], seed=42)\n",
    "print(\"===== \\t MLPClassifier Before Training \\t =====\")\n",
    "print(MLPClassifier.forward(X_train))\n",
    "MLPClassifier.train(X_train, Y_train, epochs=3000, learning_rate=0.01)\n",
    "print(\"===== \\t MLPClassifier After Training \\t =====\")\n",
    "print(MLPClassifier.forward(X_train))\n",
    "print(\"===== \\t Groud Truth \\t =====\")\n",
    "print(Y_train)\n",
    "MLPClassifier.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 用训练数据训练网络，用测试数据测试训练结果\n",
    "（注：运行多次观察结果是否变化思考原因）\n",
    "\n",
    "不变化（因为里面的权值已经固定了，所以每次运行的结果都是一样的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32220249 0.11853167 0.11853167 0.32220249 0.11853167]\n",
      " [0.11853167 0.32220249 0.32220249 0.11853167 0.11853167]\n",
      " [0.11853166 0.32220247 0.32220247 0.11853166 0.11853174]\n",
      " [0.32228694 0.1194896  0.32109667 0.11856274 0.11856406]\n",
      " [0.26793449 0.09859097 0.26688554 0.09859096 0.26799803]]\n",
      "===== \t Groud Truth \t =====\n",
      "[[1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "TEST_NUM_1 = np.array([[0,0,1,1,0],[0,0,1,1,0],[0,1,0,1,0],[0,0,0,1,0],[0,1,1,1,0]])\n",
    "TEST_NUM_2 = np.array([[1,1,1,1,0],[0,0,0,0,1],[0,1,1,1,0],[1,0,0,0,1],[1,1,1,1,1]])\n",
    "TEST_NUM_3 = np.array([[1,1,1,1,0],[0,0,0,0,1],[0,1,1,1,0],[1,0,0,0,1],[1,1,1,1,0]])\n",
    "TEST_NUM_4 = np.array([[0,1,1,1,0],[0,1,0,0,0],[0,1,1,1,0],[0,0,0,1,0],[0,1,1,1,0]])\n",
    "TEST_NUM_5 = np.array([[0,1,1,1,1],[0,1,0,0,0],[0,1,1,1,0],[0,0,0,1,0],[1,1,1,1,0]])\n",
    "\n",
    "TEST_X = np.array([TEST_NUM_1, TEST_NUM_2, TEST_NUM_3, TEST_NUM_4, TEST_NUM_5]).reshape(5,-1)\n",
    "\n",
    "TEST_Y = np.array([[1,0,0,0,0],[0,0,1,0,0],[0,0,1,0,0],[0,0,0,0,1],[0,0,0,0,1]])\n",
    "\n",
    "print(MLPClassifier.forward(TEST_X))\n",
    "print(\"===== \\t Groud Truth \\t =====\")\n",
    "print(TEST_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 构建其它测试数据构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32220249 0.11853167 0.11853167 0.32220249 0.11853167]\n",
      " [0.11853167 0.32220249 0.32220249 0.11853167 0.11853167]\n",
      " [0.11853166 0.32220247 0.32220247 0.11853166 0.11853174]\n",
      " [0.32228694 0.1194896  0.32109667 0.11856274 0.11856406]\n",
      " [0.26793449 0.09859097 0.26688554 0.09859096 0.26799803]]\n",
      "===== \t Groud Truth \t =====\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "N_TEST_NUM_1 = np.array([[0,0,0,1,0],[0,0,1,1,0],[0,1,0,1,0],[0,0,0,1,0],[0,0,0,1,0]])\n",
    "N_TEST_NUM_2 = np.array([[0,1,1,1,0],[0,0,0,0,1],[0,1,1,1,0],[1,0,0,0,0],[1,1,1,0,0]])\n",
    "N_TEST_NUM_3 = np.array([[0,1,1,1,0],[0,0,0,0,1],[0,1,1,1,0],[0,0,0,0,1],[0,1,1,1,0]])\n",
    "N_TEST_NUM_4 = np.array([[0,0,0,1,0],[0,0,1,1,0],[0,1,0,1,0],[0,1,1,1,0],[0,0,0,1,0]])\n",
    "N_TEST_NUM_5 = np.array([[0,1,1,1,0],[0,1,0,0,0],[0,1,1,1,0],[0,0,0,1,0],[0,1,1,1,0]])\n",
    "\n",
    "N_TEST_X = np.array([TEST_NUM_1, TEST_NUM_2, TEST_NUM_3, TEST_NUM_4, TEST_NUM_5]).reshape(5,-1)\n",
    "\n",
    "N_TEST_Y = np.array([[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]])\n",
    "\n",
    "print(MLPClassifier.forward(N_TEST_X))\n",
    "print(\"===== \\t Groud Truth \\t =====\")\n",
    "print(N_TEST_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12  练习12：补全上述代码，观察训练结果是否有效。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_with_RELU:\n",
    "    def __init__(self, in_hidden_out:list, if_bias=False, seed=None):\n",
    "        self.input_size = in_hidden_out[0]\n",
    "        self.output_size = in_hidden_out[-1]\n",
    "        self.hidden_layers = len(in_hidden_out) - 2\n",
    "        self.in_hidden_out = in_hidden_out\n",
    "        self.if_bias = if_bias\n",
    "        self.seed = seed\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.loss = []\n",
    "        self.activations = []\n",
    "        self.num_classes = in_hidden_out[-1]\n",
    "\n",
    "\n",
    "        self.initialize_weights_and_biases()\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    \n",
    "    def corss_entropy(self, y_pred, y_true):\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "\n",
    "    def MSD(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "    \n",
    "\n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / exp_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    def initialize_weights_and_biases(self):\n",
    "        if self.seed:\n",
    "            np.random.seed(self.seed)\n",
    "        for i in range(self.hidden_layers + 1):\n",
    "            self.weights.append(np.random.rand(self.in_hidden_out[i], self.in_hidden_out[i+1]) * 2 -1)\n",
    "            if self.if_bias:\n",
    "                self.biases.append(np.random.rand((1, self.in_hidden_out[i+1]))*2 -1)\n",
    "            else:\n",
    "                self.biases.append(np.zeros((1, self.in_hidden_out[i+1])))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(self.hidden_layers + 1):\n",
    "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            # a = self.sigmoid(z)\n",
    "            a = self.ReLU(z)\n",
    "            self.activations.append(a)\n",
    "        # softmax output layer\n",
    "        self.activations[-1] = self.softmax(self.activations[-1])\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        _ = self.forward(X)\n",
    "        error = y - self.activations[-1]\n",
    "\n",
    "        self.loss.append(self.corss_entropy(self.activations[-1], y))\n",
    "\n",
    "        delta = error\n",
    "        self.weights[-1] += learning_rate * np.dot(self.activations[-2].T, delta)\n",
    "        if self.if_bias:\n",
    "            self.biases[-1] += learning_rate * np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "        for i in range(self.hidden_layers, 0, -1):\n",
    "            # delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            delta = np.dot(delta, self.weights[i].T) * self.ReLU(self.activations[i]).astype(int)\n",
    "            self.weights[i-1] += learning_rate * np.dot(self.activations[i-1].T, delta)\n",
    "            if self.if_bias:\n",
    "                self.biases[i-1] += learning_rate * np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for _ in range(epochs):\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== \t MLPClassifier Before Training \t =====\n",
      "[[0.058592   0.058592   0.765632   0.058592   0.058592  ]\n",
      " [0.32502647 0.06552917 0.47838603 0.06552917 0.06552917]\n",
      " [0.22597745 0.09490868 0.44370421 0.09490868 0.14050098]\n",
      " [0.00689348 0.00689348 0.56355274 0.00689348 0.41576682]\n",
      " [0.13747229 0.13747229 0.45011086 0.13747229 0.13747229]]\n",
      "===== \t MLPClassifier After Training \t =====\n",
      "[[9.99794348e-01 1.92287439e-05 1.47965399e-04 1.92287439e-05\n",
      "  1.92287439e-05]\n",
      " [1.06277579e-05 9.99649717e-01 3.18399248e-04 1.06277579e-05\n",
      "  1.06277579e-05]\n",
      " [4.82666689e-05 2.88007531e-04 9.99441320e-01 3.32516753e-05\n",
      "  1.89154615e-04]\n",
      " [3.15360477e-05 3.15360477e-05 3.15360477e-05 9.99873856e-01\n",
      "  3.15360477e-05]\n",
      " [3.12507061e-05 3.12507061e-05 1.30000314e-04 3.12507061e-05\n",
      "  9.99776248e-01]]\n",
      "===== \t Groud Truth \t =====\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ReLU_MLP = MLP_with_RELU([25, 50, 5], seed=42)\n",
    "print(\"===== \\t MLPClassifier Before Training \\t =====\")\n",
    "print(ReLU_MLP.forward(X_train))\n",
    "ReLU_MLP.train(X_train, Y_train, epochs=3000, learning_rate=0.01)\n",
    "print(\"===== \\t MLPClassifier After Training \\t =====\")\n",
    "print(ReLU_MLP.forward(X_train))\n",
    "print(\"===== \\t Groud Truth \\t =====\")\n",
    "print(Y_train)\n",
    "ReLU_MLP.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习13：重复运行多次主函数，观察训练结果是否有差异？思考其中原因和改善方法\n",
    "\n",
    "\n",
    "这里不理解老师所说的重复运行多次主函数什么意思，给定了网络和随机数种子，以及指定数据集，训练的结果就应该是固定的。\n",
    "\n",
    "所以不明白差异体现在哪里。\n",
    "\n",
    "这里是指Sigmoid函数 vs ReLU 函数的区别吗？\n",
    "\n",
    "ReLU比Sigmoid的优点是它能解决梯度消失问题，以及计算效率高，ReLU在正区间上是线性的，因此训练速度较快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 练习14：比较两种结构的优劣，结合本例比较两者的训练结果，并对结果进行分析。（提示：ReLU真的好吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== \t MLP_ReLU Training \t =====\n",
      "[[9.9979435e-01 1.9230000e-05 1.4797000e-04 1.9230000e-05 1.9230000e-05]\n",
      " [1.0630000e-05 9.9964972e-01 3.1840000e-04 1.0630000e-05 1.0630000e-05]\n",
      " [4.8270000e-05 2.8801000e-04 9.9944132e-01 3.3250000e-05 1.8915000e-04]\n",
      " [3.1540000e-05 3.1540000e-05 3.1540000e-05 9.9987386e-01 3.1540000e-05]\n",
      " [3.1250000e-05 3.1250000e-05 1.3000000e-04 3.1250000e-05 9.9977625e-01]]\n",
      "===== \t MLP Training \t =====\n",
      "[[0.40460968 0.14884758 0.14884758 0.14884758 0.14884758]\n",
      " [0.14596971 0.3967701  0.16533306 0.14596356 0.14596356]\n",
      " [0.12435813 0.15426087 0.33804044 0.12435813 0.25898243]\n",
      " [0.14884758 0.14884758 0.14884758 0.40460968 0.14884758]\n",
      " [0.13878774 0.13878774 0.20637258 0.13878774 0.37726419]]\n",
      "===== \t Groud Truth \t =====\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== \\t MLP_ReLU Training \\t =====\")\n",
    "print(np.round(ReLU_MLP.forward(X_train), 8))\n",
    "print(\"===== \\t MLP Training \\t =====\")\n",
    "print(MLPClassifier.forward(X_train))\n",
    "print(\"===== \\t Groud Truth \\t =====\")\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本例的结果来看，ReLU比Sigmoid更好地拟合了数据，并且在训练集和测试集上的表现都很好。\n",
    "\n",
    "但是ReLU也有死亡问题，即在某些情况下，ReLU的梯度会变成0，导致网络无法学习到有效的特征。因此，在实际使用中，我们通常会使用LeakyReLU或ELU等激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 补全Dropout相关代码，得到训练结果 \n",
    "## 16 Dropout+ReLU如何实现?\n",
    "\n",
    "这里我两个一起实现了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_with_ReLU_Dropout(object):\n",
    "    def __init__(self, in_hidden_out:list, if_bias=False, seed=None, dropout_rate=0.5):\n",
    "        self.input_size = in_hidden_out[0]\n",
    "        self.output_size = in_hidden_out[-1]\n",
    "        self.hidden_layers = len(in_hidden_out) - 2\n",
    "        self.in_hidden_out = in_hidden_out\n",
    "        self.if_bias = if_bias\n",
    "        self.seed = seed\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.loss = []\n",
    "        self.activations = []\n",
    "        self.num_classes = in_hidden_out[-1]\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "\n",
    "        self.initialize_weights_and_biases()\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    \n",
    "    def corss_entropy(self, y_pred, y_true):\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "\n",
    "    def MSD(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true)**2)\n",
    "    \n",
    "\n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "\n",
    "    def Dropout(self, x, p=0.5):\n",
    "        mask = np.random.rand(*x.shape) < p\n",
    "        return x * mask / p\n",
    "\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / exp_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    def initialize_weights_and_biases(self):\n",
    "        if self.seed:\n",
    "            np.random.seed(self.seed)\n",
    "        for i in range(self.hidden_layers + 1):\n",
    "            self.weights.append(np.random.rand(self.in_hidden_out[i], self.in_hidden_out[i+1]) * 2 -1)\n",
    "            if self.if_bias:\n",
    "                self.biases.append(np.random.rand((1, self.in_hidden_out[i+1]))*2 -1)\n",
    "            else:\n",
    "                self.biases.append(np.zeros((1, self.in_hidden_out[i+1])))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        for i in range(self.hidden_layers + 1):\n",
    "            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]\n",
    "            # a = self.sigmoid(z)\n",
    "            a = self.ReLU(z)\n",
    "            a = self.Dropout(a, self.dropout_rate)  # dropout forward pass\n",
    "            self.activations.append(a)\n",
    "        # softmax output layer\n",
    "        self.activations[-1] = self.softmax(self.activations[-1])\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        _ = self.forward(X)\n",
    "        error = y - self.activations[-1]\n",
    "\n",
    "        self.loss.append(self.corss_entropy(self.activations[-1], y))\n",
    "\n",
    "        delta = error\n",
    "        self.weights[-1] += learning_rate * np.dot(self.activations[-2].T, delta)\n",
    "        if self.if_bias:\n",
    "            self.biases[-1] += learning_rate * np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "        for i in range(self.hidden_layers, 0, -1):\n",
    "            # delta = np.dot(delta, self.weights[i].T) * self.sigmoid_derivative(self.activations[i])\n",
    "            delta = np.dot(delta, self.weights[i].T) * self.ReLU(self.activations[i]).astype(int)\n",
    "            delta = self.Dropout(delta, self.dropout_rate) # dropout backward pass\n",
    "            self.weights[i-1] += learning_rate * np.dot(self.activations[i-1].T, delta)\n",
    "            if self.if_bias:\n",
    "                self.biases[i-1] += learning_rate * np.sum(delta, axis=0, keepdims=True)\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for _ in range(epochs):\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== \t MLPClassifier Before Training \t =====\n",
      "[[0.2   0.2   0.2   0.2   0.2  ]\n",
      " [0.2   0.2   0.2   0.2   0.2  ]\n",
      " [0.    0.    0.    0.912 0.088]\n",
      " [0.2   0.2   0.2   0.2   0.2  ]\n",
      " [0.004 0.004 0.984 0.004 0.004]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeffey\\AppData\\Local\\Temp/ipykernel_62760/3996595683.py:27: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
      "C:\\Users\\Jeffey\\AppData\\Local\\Temp/ipykernel_62760/3996595683.py:27: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== \t MLPClassifier After Training \t =====\n",
      "[[0.997 0.001 0.001 0.001 0.001]\n",
      " [0.545 0.114 0.114 0.114 0.114]\n",
      " [0.003 0.003 0.99  0.003 0.003]\n",
      " [0.2   0.2   0.2   0.2   0.2  ]\n",
      " [0.    0.    0.001 0.    0.997]]\n",
      "===== \t Groud Truth \t =====\n",
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ReLU_Dropout_MLP = MLP_with_ReLU_Dropout([25, 50, 5], dropout_rate=0.5)\n",
    "print(\"===== \\t MLPClassifier Before Training \\t =====\")\n",
    "print(np.round(ReLU_Dropout_MLP.forward(X_train),3))\n",
    "ReLU_Dropout_MLP.train(X_train, Y_train, epochs=3000, learning_rate=0.01)\n",
    "print(\"===== \\t MLPClassifier After Training \\t =====\")\n",
    "print(np.round(ReLU_Dropout_MLP.forward(X_train),3))\n",
    "print(\"===== \\t Groud Truth \\t =====\")\n",
    "print(Y_train)\n",
    "ReLU_Dropout_MLP.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
